# Indian Sign Language Recognition System

## ğŸ“– Introduction
This project presents a **computer vision and deep learningâ€“based Indian Sign Language (ISL) Recognition System** that detects hand gestures using a webcam and recognizes **alphabets (Aâ€“Z) and digits (1â€“9)**.  
The system also converts recognized signs into **voice output**, enabling better communication between hearing-impaired users and nonâ€“sign-language users.

---

## â“ Problem Statement
Communication between hearing-impaired individuals and the general public is often challenging due to limited understanding of sign language.  
This project aims to bridge this gap by developing a real-time system that recognizes Indian Sign Language gestures and converts them into readable text and speech.

---

## ğŸ¯ Objectives
- To recognize Indian Sign Language alphabets (Aâ€“Z) and digits (1â€“9).
- To detect both one-hand and two-hand gestures using MediaPipe and CVZone.
- To apply deep learning techniques for accurate gesture classification.
- To generate voice output for the recognized signs.
- To provide a user-friendly interface using Streamlit.

---

## ğŸ› ï¸ Technologies Used
- **Python**
- **OpenCV**
- **MediaPipe**
- **CVZone**
- **TensorFlow / Keras**
- **NumPy**
- **Streamlit**
- **gTTS / pyttsx3**

---

## ğŸ“‚ Project Structure
HandSignDetection/ â”‚ â”œâ”€â”€ app.py â”œâ”€â”€ datacollection/ â”œâ”€â”€ Model/ â”œâ”€â”€ Data/ â”œâ”€â”€ test.py â”œâ”€â”€ requirements.txt â””â”€â”€ README.md
---

## â–¶ï¸ How to Run the Project

### Step 1: Install Required Libraries
bash
pip install -r requirements.txt

### Step 2: Run the application
bash
streamlit run app.py


**ğŸ“Š Output**
1. Real-time hand gesture detection using webcam.
2. Recognition of ISL alphabets and digits.
3. Display of recognized sign on the screen.
4. Audio output of the detected gesture.

**âš ï¸ Limitations**
- Requires proper lighting conditions.
- Accuracy may decrease with complex backgrounds.
- Limited to predefined alphabets and digits.

**ğŸš€ Future Enhancements**
. Recognition of full words and sentences.
. Support for dynamic gestures.
. Mobile application implementation.
. Improved accuracy using advanced deep learning models.
